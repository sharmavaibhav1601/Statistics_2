{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics-2\n",
        "#Theory Questions"
      ],
      "metadata": {
        "id": "iEMBUMjyLWQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics?\n",
        "-> Hypothesis testing is a statistical procedure that allows researchers to make inferences about a population based on sample data. It involves formulating two competing hypotheses: the null hypothesis (which states there is no effect or difference) and the alternative hypothesis (which suggests there is an effect or difference). Researchers collect data and apply statistical tests to determine whether the evidence is strong enough to reject the null hypothesis in favor of the alternative. This process helps in making informed decisions and conclusions based on empirical evidence.\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "-> The null hypothesis, denoted as $$H_0$$, is a statement asserting that there is no significant effect or difference in a given context, serving as a default position. In contrast, the alternative hypothesis, denoted as $$H_a$$ or $$H_1$$, posits that there is a significant effect or difference. The null hypothesis is tested against the alternative hypothesis, and the outcome of the hypothesis test determines whether there is sufficient evidence to reject $$H_0$$. Understanding the distinction between these hypotheses is crucial for interpreting statistical results and making valid conclusions.\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "-> The significance level, denoted as $$\\alpha$$, is a threshold set by the researcher before conducting a hypothesis test. It represents the probability of making a Type I error, which occurs when the null hypothesis is incorrectly rejected when it is true. Common significance levels are 0.05 and 0.01, indicating a 5% or 1% risk of committing a Type I error, respectively. The significance level is important because it helps researchers determine the criteria for rejecting the null hypothesis, guiding the interpretation of results and ensuring that findings are statistically meaningful and reliable.\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "-> The P-value is a statistical measure that helps determine the strength of evidence against the null hypothesis. It quantifies the probability of observing the collected data, or something more extreme, assuming that the null hypothesis is true. A smaller P-value indicates stronger evidence against $$H_0$$. Researchers compare the P-value to the predetermined significance level ($$\\alpha$$) to decide whether to reject or fail to reject the null hypothesis. If the P-value is less than or equal to $$\\alpha$$, it suggests that the observed effect is statistically significant, warranting further investigation or action.\n",
        "\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "-> Interpreting the P-value involves comparing it to the significance level ($$\\alpha$$) established prior to the test. If the P-value is less than or equal to $$\\alpha$$, it indicates that the observed data is unlikely under the null hypothesis, leading to its rejection. This suggests that there is sufficient evidence to support the alternative hypothesis. Conversely, if the P-value is greater than $$\\alpha$$, it implies that the data does not provide strong enough evidence to reject the null hypothesis, and researchers may conclude that any observed effect could be due to random chance.\n",
        "\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "-> Type I and Type II errors are two potential mistakes that can occur in hypothesis testing. A Type I error occurs when the null hypothesis is rejected when it is actually true, leading to a false positive conclusion. The probability of making a Type I error is denoted by the significance level ($$\\alpha$$). On the other hand, a Type II error occurs when the null hypothesis is not rejected when it is false, resulting in a false negative conclusion. The probability of making a Type II error is denoted by $$\\beta$$. Understanding these errors is crucial for evaluating the reliability of hypothesis tests.\n",
        "\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "-> A one-tailed test is a hypothesis test that evaluates the possibility of the relationship in one direction, either greater than or less than a certain value. For example, it tests if a new drug is more effective than an existing one. In contrast, a two-tailed test assesses the possibility of a relationship in both directions, testing whether a new drug is either more effective or less effective than the existing one. The choice between one-tailed and two-tailed tests depends on the research question and the specific hypotheses being tested, influencing the interpretation of results.\n",
        "\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "-> The Z-test is a statistical test used to determine whether there is a significant difference between the means of a sample and a population or between two sample means. It is applicable when the population variance is known and the sample size is large (typically n >= 30). The Z-test assumes that the sampling distribution of the sample mean is approximately normal due to the Central Limit Theorem. Researchers use the Z-test to calculate the Z-score, which indicates how many standard deviations the sample mean is from the population mean, allowing for hypothesis testing regarding population parameters.\n",
        "\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "-> The Z-score is calculated using the formula: $$ Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}} $$, where $$\\bar{x}$$ is the sample mean, $$\\mu$$ is the population mean, $$\\sigma$$ is the population standard deviation, and $$n$$ is the sample size. The Z-score represents the number of standard deviations the sample mean is from the population mean. In hypothesis testing, the Z-score is used to determine the probability of observing a sample mean as extreme as the one obtained, given that the null hypothesis is true. It helps assess whether to reject or fail to reject the null hypothesis.\n",
        "\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "-> The T-distribution is a probability distribution that is used in hypothesis testing when the sample size is small (n < 30) and the population variance is unknown. It is similar to the normal distribution but has heavier tails, which accounts for the increased variability expected in smaller samples. The T-distribution becomes closer to the normal distribution as the sample size increases. Researchers use the T-distribution to perform T-tests, allowing for valid inferences about population means when the sample size is limited and the population standard deviation is not known.\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "-> The primary difference between a Z-test and a T-test lies in the conditions under which each test is used. A Z-test is appropriate when the population variance is known and the sample size is large (n >= 30), allowing for the use of the normal distribution. In contrast, a T-test is used when the population variance is unknown and the sample size is small (n < 30). The T-test relies on the T-distribution, which accounts for the additional uncertainty associated with estimating the population variance from a small sample. This distinction is crucial for accurate hypothesis testing.\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "-> The T-test is a statistical test used to determine whether there is a significant difference between the means of two groups or between a sample mean and a population mean. There are different types of T-tests, including the one-sample T-test, independent two-sample T-test, and paired T-test. The one-sample T-test compares the sample mean to a known population mean, while the independent two-sample T-test compares the means of two independent groups. The paired T-test is used for related samples. Researchers calculate the T-statistic and compare it to critical values from the T-distribution to make decisions about the null hypothesis.\n",
        "\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "-> The Z-test and T-test are both used to compare sample means to population means or between two sample means, but they differ in their application based on sample size and variance knowledge. The Z-test is used when the population variance is known and the sample size is large, while the T-test is used when the population variance is unknown and the sample size is small. As the sample size increases, the T-distribution approaches the normal distribution, making the Z-test and T-test yield similar results. Understanding when to use each test is essential for accurate hypothesis testing and valid conclusions.\n",
        "\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "-> A confidence interval is a range of values that is used to estimate the true population parameter with a specified level of confidence, typically 95% or 99%. It is calculated from sample data and provides an interval within which the true parameter is likely to fall. For example, a 95% confidence interval suggests that if the same sampling procedure were repeated multiple times, approximately 95% of the calculated intervals would contain the true population parameter. Confidence intervals are useful for interpreting statistical results, as they provide a measure of uncertainty and help researchers understand the precision of their estimates.\n",
        "\n",
        "15. What is the margin of error, and how does it affect the confidence interval?\n",
        "-> The margin of error is the amount of error that is allowed in the estimation of a population parameter, reflecting the precision of the estimate. It is calculated based on the standard error of the sample mean and the critical value from the relevant distribution (Z or T). The margin of error directly affects the width of the confidence interval; a larger margin of error results in a wider interval, indicating greater uncertainty about the estimate. Conversely, a smaller margin of error leads to a narrower confidence interval, suggesting more precision. Researchers must balance the margin of error with the desired level of confidence.\n",
        "\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "-> Bayes' Theorem is a fundamental concept in statistics that describes how to update the probability of a hypothesis based on new evidence. It combines prior knowledge (prior probability) with new data (likelihood) to produce an updated probability (posterior probability). The theorem is expressed mathematically as: $$ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} $$, where $$P(H|E)$$ is the posterior probability, $$P(E|H)$$ is the likelihood, $$P(H)$$ is the prior probability, and $$P(E)$$ is the marginal likelihood. Bayes' Theorem is significant because it provides a systematic way to incorporate new information into statistical analysis, making it a powerful tool in various fields, including medical diagnosis, machine learning, and decision-making.\n",
        "\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "-> The Chi-square distribution is a probability distribution that arises in statistics when analyzing categorical data. It is used primarily in tests of independence and goodness of fit. The distribution is characterized by its degrees of freedom, which depend on the number of categories or groups being analyzed. The Chi-square distribution is positively skewed, especially with fewer degrees of freedom. Researchers use the Chi-square test to determine whether there is a significant association between categorical variables or to assess how well observed frequencies match expected frequencies. It is a crucial tool for analyzing categorical data in various research contexts.\n",
        "\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "-> The Chi-square goodness of fit test is a statistical test used to determine whether the observed frequencies of a categorical variable match the expected frequencies based on a specific hypothesis. It assesses how well a theoretical distribution fits the observed data. To apply the test, researchers calculate the Chi-square statistic using the formula: $$ \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} $$, where $$O_i$$ is the observed frequency and $$E_i$$ is the expected frequency for each category. The calculated Chi-square statistic is then compared to the critical value from the Chi-square distribution table, based on the degrees of freedom, to determine statistical significance.\n",
        "\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "-> The F-distribution is a probability distribution that arises in the context of comparing variances between two or more groups. It is used primarily in analysis of variance (ANOVA) and regression analysis. The F-distribution is characterized by two sets of degrees of freedom: one for the numerator (between-group variability) and one for the denominator (within-group variability). Researchers use the F-distribution to test hypotheses about the equality of variances or to assess the overall significance of a regression model. The F-test helps determine whether the observed variability among group means is greater than would be expected by chance alone.\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "-> ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to determine if there are any statistically significant differences among them. The test assesses whether the variability between group means is greater than the variability within groups. ANOVA has several assumptions, including independence of observations, normality of the data within each group, and homogeneity of variances (equal variances across groups). If these assumptions are met, ANOVA can provide valid results. If not, researchers may need to consider alternative methods or transformations to meet the assumptions before conducting the test.\n",
        "\n",
        "21. What are the different types of ANOVA tests?\n",
        "-> There are several types of ANOVA tests, each designed for specific research scenarios. The most common types include:\n",
        "\n",
        "* One-way ANOVA: Compares the means of three or more independent groups based on one independent variable.\n",
        "* Two-way ANOVA: Examines the effects of two independent variables on a dependent variable, allowing for interaction effects between the variables.\n",
        "* Repeated measures ANOVA: Used when the same subjects are measured multiple times under different conditions, assessing within-subject variability.\n",
        "* MANOVA (Multivariate ANOVA): Extends ANOVA to multiple dependent variables, testing for differences in group means across several outcomes simultaneously. Each type of ANOVA has specific assumptions and applications, making it essential to choose the appropriate test based on the research design.\n",
        "\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "-> The F-test is a statistical test used to compare the variances of two or more groups to determine if they are significantly different. It is commonly used in the context of ANOVA to assess whether the variability between group means is greater than the variability within groups. The F-test calculates the F-statistic, which is the ratio of the variance between groups to the variance within groups. If the F-statistic is significantly larger than expected under the null hypothesis (which states that all group variances are equal), researchers can reject the null hypothesis, indicating that at least one group mean is different. The F-test is a critical component of hypothesis testing in various statistical analyses.\n",
        "\n"
      ],
      "metadata": {
        "id": "Llx9W7wSLeDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Z-test for comparing a sample mean to a known population mean\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to perform a Z-test\n",
        "def z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Perform the Z-test\n",
        "z_score, p_value = z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")"
      ],
      "metadata": {
        "id": "5arfPky1cHLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Function to perform a Z-test\n",
        "def z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Perform the Z-test\n",
        "z_score, p_value = z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "3UH4ZYo7b4Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to perform a one-sample Z-test\n",
        "def one_sample_z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Perform the one-sample Z-test\n",
        "z_score, p_value = one_sample_z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "AuAyqwLQbWGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to perform a two-tailed Z-test\n",
        "def two_tailed_z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Perform the two-tailed Z-test\n",
        "z_score, p_value = two_tailed_z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Visualize the decision region\n",
        "alpha = 0.05  # Significance level\n",
        "z_critical = stats.norm.ppf(1 - alpha/2)  # Critical value for two-tailed test\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = stats.norm.pdf(x)\n",
        "\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "plt.fill_between(x, 0, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.5, label='Rejection Region')\n",
        "plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "plt.title('Two-tailed Z-test Decision Region')\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vZWSJhPxbOhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to calculate and visualize Type 1 and Type 2 errors\n",
        "def visualize_type_errors(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "    # Calculate critical values\n",
        "    z_critical = stats.norm.ppf(1 - alpha/2)  # Critical value for two-tailed test\n",
        "\n",
        "    # Visualize the decision region and errors\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = stats.norm.pdf(x)\n",
        "\n",
        "    plt.plot(x, y, label='Standard Normal Distribution')\n",
        "    plt.fill_between(x, 0, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.5, label='Type I Error (α)')\n",
        "    plt.fill_between(x, 0, y, where=(x > -z_critical) & (x < z_critical), color='green', alpha=0.5, label='Type II Error (β)')\n",
        "    plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "    plt.title('Type I and Type II Errors')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return z_score, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Visualize Type 1 and Type 2 errors\n",
        "z_score, p_value = visualize_type_errors(sample_data, population_mean, population_std)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "_zbhSNdfaGzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a Python program to perform an independent T-test and interpret the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to perform an independent T-test\n",
        "def independent_t_test(sample1, sample2):\n",
        "    t_statistic, p_value = stats.ttest_ind(sample1, sample2)\n",
        "    return t_statistic, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Sample 1\n",
        "sample2 = np.random.normal(loc=55, scale=10, size=30)  # Sample 2\n",
        "\n",
        "# Perform the independent T-test\n",
        "t_statistic, p_value = independent_t_test(sample1, sample2)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The means of the two samples are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The means of the two samples are not significantly different.\")"
      ],
      "metadata": {
        "id": "PCMyVt5CZswK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Perform a paired sample T-test using Python and visualize the comparison results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to perform a paired sample T-test\n",
        "def paired_t_test(sample1, sample2):\n",
        "    t_statistic, p_value = stats.ttest_rel(sample1, sample2)\n",
        "    return t_statistic, p_value\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Sample 1\n",
        "sample2 = sample1 + np.random.normal(loc=5, scale=5, size=30)  # Sample 2 with a shift\n",
        "\n",
        "# Perform the paired sample T-test\n",
        "t_statistic, p_value = paired_t_test(sample1, sample2)\n",
        "\n",
        "# Print the results\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Visualize the comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sample1, label='Sample 1', marker='o')\n",
        "plt.plot(sample2, label='Sample 2', marker='o')\n",
        "plt.title('Comparison of Paired Samples')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hkhJ-LBZZWW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Function to perform a Z-test\n",
        "def z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Function to perform an independent T-test\n",
        "def independent_t_test(sample_data, population_mean):\n",
        "    t_statistic, p_value = stats.ttest_1samp(sample_data, population_mean)\n",
        "    return t_statistic, p_value\n",
        "\n",
        "# Perform the Z-test\n",
        "z_score, p_value_z = z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Perform the T-test\n",
        "t_statistic, p_value_t = independent_t_test(sample_data, population_mean)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-test: Z-score = {z_score}, P-value = {p_value_z}\")\n",
        "print(f\"T-test: T-statistic = {t_statistic}, P-value = {p_value_t}\")"
      ],
      "metadata": {
        "id": "9_LrcG9jZJ5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to calculate the confidence interval\n",
        "def confidence_interval(sample_data, confidence_level=0.95):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    sample_std = np.std(sample_data, ddof=1)  # Sample standard deviation\n",
        "    z_critical = stats.norm.ppf((1 + confidence_level) / 2)  # Z critical value for the confidence level\n",
        "    margin_of_error = z_critical * (sample_std / np.sqrt(sample_size))\n",
        "    return sample_mean - margin_of_error, sample_mean + margin_of_error\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "\n",
        "# Calculate the confidence interval\n",
        "ci_lower, ci_upper = confidence_interval(sample_data)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Confidence Interval: ({ci_lower}, {ci_upper})\")"
      ],
      "metadata": {
        "id": "pBD0WsaAYJnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to calculate the margin of error\n",
        "def margin_of_error(sample_data, confidence_level=0.95):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    sample_std = np.std(sample_data, ddof=1)  # Sample standard deviation\n",
        "    z_critical = stats.norm.ppf((1 + confidence_level) / 2)  # Z critical value for the confidence level\n",
        "    margin_of_error = z_critical * (sample_std / np.sqrt(sample_size))\n",
        "    return margin_of_error\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "\n",
        "# Calculate the margin of error\n",
        "me = margin_of_error(sample_data)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Margin of Error: {me}\")"
      ],
      "metadata": {
        "id": "uAxk75SvYDnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "# Function to perform Bayesian inference using Bayes' Theorem\n",
        "def bayesian_inference(prior, likelihood, evidence):\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Example values\n",
        "prior = 0.3  # Prior probability of hypothesis\n",
        "likelihood = 0.8  # Likelihood of evidence given hypothesis\n",
        "evidence = 0.5  # Total probability of evidence\n",
        "\n",
        "# Calculate posterior probability\n",
        "posterior = bayesian_inference(prior, likelihood, evidence)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Posterior Probability: {posterior}\")"
      ],
      "metadata": {
        "id": "RAGjEGjFX7wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Perform a Chi-square test for independence between two categorical variables in Python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulated data for two categorical variables\n",
        "data = np.array([[10, 20, 30],\n",
        "                 [20, 15, 25]])\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(data)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square Statistic: {chi2_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"Expected Frequencies: \\n{expected}\")"
      ],
      "metadata": {
        "id": "Y2To0TA0XSGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate expected frequencies\n",
        "def expected_frequencies(observed):\n",
        "    total = np.sum(observed)\n",
        "    row_totals = np.sum(observed, axis=1)\n",
        "    col_totals = np.sum(observed, axis=0)\n",
        "    expected = np.outer(row_totals, col_totals) / total\n",
        "    return expected\n",
        "\n",
        "# Simulated observed data\n",
        "observed = np.array([[10, 20, 30],\n",
        "                     [20, 15, 25]])\n",
        "\n",
        "# Calculate expected frequencies\n",
        "expected = expected_frequencies(observed)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Expected Frequencies: \\n{expected}\")"
      ],
      "metadata": {
        "id": "lS7E8wbNWwt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulated observed data\n",
        "observed = np.array([10, 20, 30, 40])\n",
        "expected = np.array([15, 25, 35, 25])  # Expected frequencies\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_statistic, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square Statistic: {chi2_statistic}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "ZShztCbwWsKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Parameters for Chi-square distribution\n",
        "df = 2  # Degrees of freedom\n",
        "x = np.linspace(0, 20, 1000)\n",
        "y = stats.chi2.pdf(x, df)\n",
        "\n",
        "# Plot the Chi-square distribution\n",
        "plt.plot(x, y, label=f'Chi-square Distribution (df={df})')\n",
        "plt.title('Chi-square Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OIgfITnBVWBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16. Implement an F-test using Python to compare the variances of two random samples\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Sample 1\n",
        "sample2 = np.random.normal(loc=55, scale=15, size=30)  # Sample 2\n",
        "\n",
        "# Perform F-test\n",
        "f_statistic = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
        "dof1 = len(sample1) - 1\n",
        "dof2 = len(sample2) - 1\n",
        "p_value = 1 - stats.f.cdf(f_statistic, dof1, dof2)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "t4KhTCxSVRDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between group means.\")"
      ],
      "metadata": {
        "id": "YVy1rYwaVKbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate random data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Plot the results\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title('One-way ANOVA')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2aZB4sIQVALl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to check assumptions for ANOVA\n",
        "def check_anova_assumptions(groups):\n",
        "    # Check normality using Shapiro-Wilk test\n",
        "    normality_results = {f'Group {i+1}': stats.shapiro(group) for i, group in enumerate(groups)}\n",
        "\n",
        "    # Check equal variance using Levene's test\n",
        "    levene_statistic, levene_p_value = stats.levene(*groups)\n",
        "\n",
        "    return normality_results, levene_statistic, levene_p_value\n",
        "\n",
        "# Simulate random data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Check assumptions\n",
        "normality_results, levene_statistic, levene_p_value = check_anova_assumptions([group1, group2, group3])\n",
        "\n",
        "# Print the results\n",
        "print(\"Normality Test Results:\")\n",
        "for group, result in normality_results.items():\n",
        "    print(f\"{group}: W-statistic = {result.statistic}, p-value = {result.pvalue}\")\n",
        "\n",
        "print(f\"Levene's Test: Statistic = {levene_statistic}, p-value = {levene_p_value}\")"
      ],
      "metadata": {
        "id": "Zq5xakmtU6pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.graphics.factorplots import interaction_plot\n",
        "\n",
        "# Step 1: Create Sample Data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Factors\n",
        "factor_A = np.repeat(['Low', 'High'], 30)  # Factor A with two levels\n",
        "factor_B = np.tile(['Type1', 'Type2', 'Type3'], 20)  # Factor B with three levels\n",
        "\n",
        "# Response variable (some random data with interaction effect)\n",
        "data_values = np.random.randn(60) + 3 * (factor_A == 'High') + 2 * (factor_B == 'Type2')\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'Factor_A': factor_A, 'Factor_B': factor_B, 'Response': data_values})\n",
        "\n",
        "# Step 2: Perform Two-Way ANOVA\n",
        "model = ols('Response ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Step 3: Display Results\n",
        "print(anova_table)\n",
        "\n",
        "# Step 4: Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Factor_A', y='Response', hue='Factor_B', data=df)\n",
        "plt.title('Boxplot of Response by Factor A and Factor B')\n",
        "plt.show()\n",
        "\n",
        "# Interaction Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "interaction_plot(df['Factor_A'], df['Factor_B'], df['Response'], markers=['o', 's', 'D'])\n",
        "plt.title('Interaction Plot of Factor A and Factor B')\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gLj750o5UEGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Parameters for F-distribution\n",
        "dof1 = 5  # Degrees of freedom for the numerator\n",
        "dof2 = 2  # Degrees of freedom for the denominator\n",
        "x = np.linspace(0, 5, 1000)\n",
        "y = stats.f.pdf(x, dof1, dof2)\n",
        "\n",
        "# Plot the F-distribution\n",
        "plt.plot(x, y, label=f'F-distribution (dof1={dof1}, dof2={dof2})')\n",
        "plt.title('F-distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjCPk78ZQ9sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate random data for three groups\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Plot the results\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title('One-way ANOVA')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RjCMYsnOQ06h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "population_mean = 55  # Known population mean\n",
        "population_std = 10   # Known population standard deviation\n",
        "\n",
        "# Function to perform a Z-test\n",
        "def z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "# Perform the Z-test\n",
        "z_score, p_value = z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "GTBxTlSFQsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Sample data with mean=50, std=10, n=30\n",
        "sample_variance = np.var(sample_data, ddof=1)  # Sample variance\n",
        "population_variance = 100  # Hypothesized population variance\n",
        "\n",
        "# Perform Chi-square test for variance\n",
        "chi2_statistic = (len(sample_data) - 1) * sample_variance / population_variance\n",
        "dof = len(sample_data) - 1\n",
        "p_value = 1 - stats.chi2.cdf(chi2_statistic, dof)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square Statistic: {chi2_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample variance is significantly different from the population variance.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The sample variance is not significantly different from the population variance.\")"
      ],
      "metadata": {
        "id": "2qLiMvUXQjjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulated data for two groups\n",
        "success_a = 30  # Number of successes in group A\n",
        "n_a = 100       # Total observations in group A\n",
        "success_b = 20  # Number of successes in group B\n",
        "n_b = 80        # Total observations in group B\n",
        "\n",
        "# Calculate proportions\n",
        "p_a = success_a / n_a\n",
        "p_b = success_b / n_b\n",
        "\n",
        "# Pooled proportion\n",
        "p_pool = (success_a + success_b) / (n_a + n_b)\n",
        "\n",
        "# Z-test for proportions\n",
        "z_score = (p_a - p_b) / np.sqrt(p_pool * (1 - p_pool) * (1/n_a + 1/n_b))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "# Print the results\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "fjoHQPsnQOoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Sample 1\n",
        "sample2 = np.random.normal(loc=55, scale=15, size=30)  # Sample 2\n",
        "\n",
        "# Perform F-test\n",
        "f_statistic = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
        "dof1 = len(sample1) - 1\n",
        "dof2 = len(sample2) - 1\n",
        "p_value = 1 - stats.f.cdf(f_statistic, dof1, dof2)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Visualize the variances\n",
        "plt.boxplot([sample1, sample2], labels=['Sample 1', 'Sample 2'])\n",
        "plt.title('Comparison of Variances')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aGkiORt1P-lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulated observed data\n",
        "observed = np.array([10, 20, 30, 40])\n",
        "expected = np.array([15, 25, 35, 25])  # Expected frequencies\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_statistic, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square Statistic: {chi2_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The observed frequencies differ significantly from the expected frequencies.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The observed frequencies do not differ significantly from the expected frequencies.\")"
      ],
      "metadata": {
        "id": "LQq9Uve3Pj4r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}